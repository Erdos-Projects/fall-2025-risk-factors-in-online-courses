{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee2f776",
   "metadata": {},
   "source": [
    "# Data Merging - Non-Streaming OULAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43941e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load libraries, necessary data\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "zipped = zipfile.ZipFile(\"C:/Users/jacma/OneDrive/school work/UMD/Data Science Boot Camp/Group Project/Data/OULAD.zip\") \n",
    "\n",
    "# may not need all of these\n",
    "assessments = pd.read_csv(zipped.open('assessments.csv')) # just info about the assessments, may not need\n",
    "courses = pd.read_csv(zipped.open('courses.csv'))\n",
    "studentAssessments = pd.read_csv(zipped.open('studentAssessment.csv'))\n",
    "studentInfo = pd.read_csv(zipped.open('studentInfo.csv'))\n",
    "studentRegistration = pd.read_csv(zipped.open('studentRegistration.csv'))\n",
    "studentVLE = pd.read_csv(zipped.open('studentVle.csv')) # virtual learning environment\n",
    "VLEdata = pd.read_csv(zipped.open('vle.csv'))\n",
    "\n",
    "assessments = assessments.rename(columns={'date': 'due_date'})\n",
    "\n",
    "# Merge studentInfo & studentRegistration dataframes \n",
    "common_columns = list(set(studentInfo.columns) & set(studentRegistration.columns)) # ['code_module','code_presentation','id_student']\n",
    "df_studentInfo=pd.merge(studentInfo, studentRegistration, how='outer', on=common_columns)\n",
    "\n",
    "# checks on merge\n",
    "assert studentInfo.shape[1] + studentRegistration.shape[1] - len(common_columns) == df_studentInfo.shape[1]\n",
    "assert studentInfo.shape[0] == studentRegistration.shape[0] == df_studentInfo.shape[0]\n",
    "\n",
    "# Merge courses with above (adds column module_presentation_length)\n",
    "common_columns = list(set(courses.columns) & set(df_studentInfo.columns)) # ['code_module', 'code_presentation']\n",
    "df_studentInfo=pd.merge(courses, df_studentInfo, how='outer', on=common_columns)\n",
    "\n",
    "# Merge assessments, studentAssessment dataframes \n",
    "common_columns = list(set(assessments.columns) & set(studentAssessments.columns)) # ['id_assessment']\n",
    "df_assessment=pd.merge(studentAssessments, assessments, how='left', on=common_columns)\n",
    "\n",
    "# Merge studentVLE, VLEdata dataframes \n",
    "common_columns = list(set(studentVLE.columns) & set(VLEdata.columns)) # ['id_site', 'code_presentation', 'code_module']\n",
    "df_vle = pd.merge(studentVLE,VLEdata, how='left', on=common_columns)\n",
    "\n",
    "# Merge df_studentInfo, df_assessment dataframes \n",
    "common_columns = list(set(df_studentInfo.columns) & set(df_assessment.columns)) # ['code_module', 'id_student', 'code_presentation']\n",
    "df_student_assessment=pd.merge(df_assessment, df_studentInfo, how='left', on=common_columns)\n",
    "\n",
    "# Downcast to smaller data types based on your column stats\n",
    "df_vle = df_vle.astype({\n",
    "    \"id_student\": \"int32\",\n",
    "    \"id_site\": \"int32\",\n",
    "    \"date\": \"int16\",\n",
    "    \"sum_click\": \"int16\",\n",
    "    \"week_from\": \"Int8\", # nullable integer type (Int8, Int16, Int32) instead of plain numpy ints allows for NaNs\n",
    "    \"week_to\": \"Int8\" # nullable integer type (Int8, Int16, Int32) instead of plain numpy ints allows for NaNs\n",
    "})\n",
    "\n",
    "df_vle[\"code_module\"] = df_vle[\"code_module\"].astype(\"category\")\n",
    "df_vle[\"code_presentation\"] = df_vle[\"code_presentation\"].astype(\"category\")\n",
    "df_vle[\"activity_type\"] = df_vle[\"activity_type\"].astype(\"category\")\n",
    "\n",
    "df_student_assessment = df_student_assessment.astype({\n",
    "    \"id_assessment\": \"int32\",\n",
    "    \"id_student\": \"int32\",\n",
    "    \"date_submitted\": \"int16\",\n",
    "    \"is_banked\": \"int8\",\n",
    "    \"module_presentation_length\": \"int16\",\n",
    "    \"num_of_prev_attempts\": \"int8\",\n",
    "    \"studied_credits\": \"int16\",\n",
    "    \"score\": \"float32\",\n",
    "    \"due_date\": \"Int16\",              # could use 'Int16' if you want integer + NaNs\n",
    "    \"weight\": \"float32\",\n",
    "    \"date_registration\": \"float32\",     # safer with NaNs\n",
    "    \"date_unregistration\": \"float32\"\n",
    "})\n",
    "\n",
    "categorical_cols = [\"code_module\", \"code_presentation\", \"assessment_type\",\"gender\", \"region\", \n",
    "                    \"highest_education\", \"imd_band\",\"age_band\", \"disability\", \"final_result\"]\n",
    "df_student_assessment[categorical_cols] = df_student_assessment[categorical_cols].astype(\"category\")\n",
    "\n",
    "# Merge df_student_assessment, df_vle dataframes \n",
    "common_columns = list(set(df_student_assessment.columns) & set(df_vle.columns)) # ['code_module', 'id_student', 'code_presentation']\n",
    "df=pd.merge(df_vle, df_student_assessment, how='left', on=common_columns)  # memory issue??\n",
    "\n",
    "# df.to_csv(\"C:/Users/jacma/OneDrive/school work/UMD/Data Science Boot Camp/Group Project/Data/merged_data.csv\", index=False)\n",
    "\n",
    "del assessments,courses,studentAssessments,studentInfo,studentRegistration,studentVLE,VLEdata,common_columns,df_vle,df_student_assessment,categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb024b",
   "metadata": {},
   "source": [
    "# Data Loading (with merged csv saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacma\\AppData\\Local\\Temp\\ipykernel_35088\\2570415648.py:17: DtypeWarning: Columns (13,16,17,18,19,20,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"C:/Users/jacma/OneDrive/school work/UMD/Data Science Boot Camp/Group Project/Data/merged_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "### Load libraries, necessary data\n",
    "import pandas as pd\n",
    "streaming = pd.read_csv(\"C:/Users/jacma/OneDrive/school work/UMD/Data Science Boot Camp/Group Project/Data/Streaming_OULAD_dataset4classes.csv\")\n",
    "# \n",
    "\n",
    "# df = pd.read_csv(\"C:/Users/jacma/OneDrive/school work/UMD/Data Science Boot Camp/Group Project/Data/merged_data.csv\")\n",
    "# date: final submission date of the assessment calculated as the number of days since the start of the module\n",
    "# sum_click: number of times a student interacts with the material in that day\n",
    "# week_from: week from which the material is planned to be used\n",
    "# week_to: week until which the material is planned to be used\n",
    "# date_submitted: date of student submission, measured as the number of days since the start of the module presentation\n",
    "# is_banked:status flag indicating that the assessment result has been transferred from a previous presentation\n",
    "# score: 0 to 100. < 40 is Fail\n",
    "# weight: % weight of the assessment. Typically, Exams are treated separately and have weight 100%; the sum of all other assessments is 100%\n",
    "# module_presentation_length:\n",
    "# num_of_previous_attempts: number times the student has attempted this module\n",
    "# studied_credits: total number of credits for the modules the student is currently studying\n",
    "# date_registration: number of days measured relative to the start of the module-presentation\n",
    "# date_unregistration: number of days measured relative to the start of the module-presentation. Students who completed course have this field empty. withdraw as final result value in studentInfo.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c737f",
   "metadata": {},
   "source": [
    "# OULAD Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4318dff",
   "metadata": {},
   "source": [
    "### Data Exploration / Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e37240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7592ede",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13853f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### histograms\n",
    "### plots of potentially related variables\n",
    "### creative plots - multiple encodings (try to demonstrate preliminary intuition of inclusion of certain variables)\n",
    "\n",
    "# color by outcome class, see if there is grouping/clusters (suggests predictability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11210d9e",
   "metadata": {},
   "source": [
    "### Modeling and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b6e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08a50ad2",
   "metadata": {},
   "source": [
    "# OULAD Merged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2e8d2",
   "metadata": {},
   "source": [
    "### Data Exploration / Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bad105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270dde6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "### assess missingness, sparseness of variables (i.e. are any mostly 0?)\n",
    "# --> missingno\n",
    "# streaming.isna().sum()\n",
    "# **many zeros**, may need to stratify / under or oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Describe Continuous Variables\n",
    "#df.iloc[:,4:].describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfecb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(1.0829562015801182),\n",
       " np.float64(1.0882488302523587),\n",
       " np.float64(1.7859835503769705),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0),\n",
       " np.float64(1.002184715558602),\n",
       " np.float64(1.0),\n",
       " np.float64(1.0593728581220014)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking Categorical variables - which vary within student\n",
    "def nominal_vary_over_time_checker(data,variables):\n",
    "    # calculate mean count of nominal variables across students, if 1, doesn't vary over time for any student\n",
    "    means = []\n",
    "    for var_name in variables:\n",
    "        count = (\n",
    "            data\n",
    "            .groupby('id_student')[var_name]\n",
    "            .nunique() # count number of unique values for current variable\n",
    "        )\n",
    "        count=count[count != 0] # exclude rows with 0, i.e. information unavailable (?)\n",
    "        means.append(count.mean()) # if the mean is 1, they all have exactly one value for the variable\n",
    "    return means\n",
    "\n",
    "\n",
    "mean_counts = nominal_vary_over_time_checker(df,[\"code_module\", \"code_presentation\", \"assessment_type\",'gender','region',\n",
    "                                                 'highest_education','imd_band','age_band','disability','final_result'])\n",
    "mean_counts\n",
    "# code module: some students were in 2 or 3, (students took 1.0829 modules on average)\n",
    "# code presentation: some students were in 2 or 3, (students took 1.08824 presentations on average)\n",
    "# assessment type: some students took 2 or 3, or none, (students took 1.7859 different types of assessments)\n",
    "# age band: some students may have aged into another band (very few students did, 1.0218)\n",
    "# final result: if students had multiple assessments/modules, they could have multiple final results (no clear interpretation, this is just average \"result consistency\")\n",
    "\n",
    "del mean_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3eaaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Describe Categorical Variables\n",
    "def variable_summary(data,cat_variables):\n",
    "    summary_dict = {}\n",
    "    for var_name in cat_variables:\n",
    "        var_info = []\n",
    "        counts = data[var_name].value_counts()\n",
    "        var_info.append(counts)\n",
    "        var_info.append(counts/counts.sum())\n",
    "        summary_dict[var_name] = var_info\n",
    "    return(summary_dict)\n",
    "\n",
    "df_unique_students = df.drop_duplicates(subset='id_student', keep='first')\n",
    "# df_unique_students.to_csv(\"C:/Users/jacma/OneDrive/school work/UMD/Data Science Boot Camp/Group Project/Data/unique_students.csv\", index=False)\n",
    "discrete_vars = variable_summary(df_unique_students,['gender','region','highest_education','imd_band','age_band','disability','final_result']) # only variables that do not vary within student,\n",
    "print(discrete_vars)\n",
    "# we have 26074 unique student IDs in the data set, but 3115 of them are missing at least one of the above variables\n",
    "# so, out of 22959 students, \n",
    "#   -52.5% are male, \n",
    "#   -around 10% from each of Scotland, East Anglian Region, South Region, London Region, \n",
    "#   -44.4% had A level or equivalent education, 38% less than A level, about 1% for each of Post-Grad qualification and no formal qualification\n",
    "#   -imd_band is somewhat uniformly distributed, all around 10% but 30-40 was 11.1% (most), 90-100 was 8.5% (least)\n",
    "#   -almost 70% were aged 0-35, 30% aged 35-55, leaving only .7% over 55\n",
    "#   -about 9.1% of the students were marked as having a disability \n",
    "#   -47% passed, 22% failed, 18% withdrawn, 13% distinction (ignores if students took multiple courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['id_student'] == 1852968].describe() # count tells us missingness\n",
    "# calculate mean std of cts variables across students, if 0, it doesn't vary over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b255729",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### discrete variables\n",
    "# Plotting the first series\n",
    "test = df_unique_students.groupby(['region', 'gender']).size().reset_index(name='count').sort_values(by='region')\n",
    "\n",
    "np.array_split(test,13)\n",
    "\n",
    "\n",
    "regions = df_unique_students['region'].unique()\n",
    "x_pos = np.arange(len(regions))\n",
    "\n",
    "plt.bar(x_pos, data_series1, label='Series 1', color='skyblue')\n",
    "plt.bar(x_pos, data_series2, bottom=data_series1, label='Series 2', color='lightcoral')\n",
    "\n",
    "# Adding labels, title, and legend\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Stacked Bar Plot Example')\n",
    "plt.xticks(x_pos, regions)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "### histograms\n",
    "### plots of potentially related variables\n",
    "### creative plots - multiple encodings (try to demonstrate preliminary intuition of inclusion of certain variables)\n",
    "\n",
    "# color by outcome class, see if there is grouping/clusters (suggests predictability)\n",
    "\n",
    "\n",
    "# separate by modules, code presentation\n",
    "\n",
    "\n",
    "# for cts variables (i.e. those that change over time), select only a certain number of students (at random) for plots\n",
    "# --> plot number of interactions against date, color by time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59751e",
   "metadata": {},
   "source": [
    "### Modeling and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb177333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d81f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
